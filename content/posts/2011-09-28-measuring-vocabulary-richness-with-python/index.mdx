---
layout: post
title: 'Measuring vocabulary richness with python'
date: 2011-09-28
categories: 'Uncategorized'
author: Swizec Teller
hero: ./img/blog-wp-content-uploads-2011-09-6192586527_c36407222c_m7.jpg
---
\[caption id="" align="alignright" width="240" caption="Image by asterix611 via Flickr"][![Pillowfights 51](./img/blog-wp-content-uploads-2011-09-6192586527_c36407222c_m7.jpg "Pillowfights 51")](http://www.flickr.com/photos/28722563@N05/6192586527)\[/caption]



In preparation for a blogpost I'm going to make some time this week I found myself wanting to somehow parametrize [vocabulary](http://en.wikipedia.org/wiki/Vocabulary "Vocabulary") richness in a piece of text.



_btw, Code at bottom ;)_



It's an interesting problem because when you read something, it's pretty easy to see when an author is using rich vocabulary, but trying to reduce this observation to a simple number turns out to be a bit of a brainfuck. It's obviously somehow related to word frequencies and it seems obvious that what we want to measure is the distribution shape of word frequencies.



Luckily googling around for about an hour turned up a clue. Way back in 1944 a statistician called [G.U. Yule](http://en.wikipedia.org/wiki/Udny_Yule) cracked this problem in a paper titled _[The statistical study of literary vocabulary](http://scholar.google.si/scholar?q=The+statistical+study+of+literary+vocabulary+&hl=sl&btnG=Iskanje)_. What he came up with is the so called Yule's K characteristic.



Wikipedia is scarce on these things, so we know we're treading strange strange ground here. Persistent searching with google scholar turned up a version of the paper that wasn't paywalled to oblivion. However since it was on google books it was missing some key pages.



Luckily what looks like a random homework for R explains perfectly how to implement Yule's K value:

> A complementary way of assessing the vocabulary difficulty of texts is to measure their lexical richness. Two indices one could use are Yule's K or Yule's I. These two are defined as follows: (1) Yule's K = 10,000⋅M 2−M 1 ÷ M 1⋅M 1 (2) Yule's I = M 1⋅M 1÷M 2−M 1  where M1 is the number of all word forms a text consists of and M2 is the sum of the products of each observed frequency to the power of two and the number of word types observed with that frequency (cf. Oakes 1998:204). For example, if one word occurs three times and four words occur five times, M2=(1\*32)+(4\*52)=109. The larger Yule's K, the smaller the diversity of the vocabulary (and thus, arguably, the easier the text). Since Yule's I is based on the reciprocal of Yule's K, the larger Yule's I, the larger the diversity of the vocabulary (and thus, arguably, the more difficult the text).

Unfortunately I don't have the link anymore. It was a seriously random pdf I found online, the title seems to be _"Quantitative [corpus linguistics](http://en.wikipedia.org/wiki/Corpus_linguistics "Corpus linguistics") with R: a practical introduction"_



In hopes this blogpost saves somebody a few hours of googling when trying to measure vocabulary richness, here's my python implementation of Yule's K characteristic (or rather its inverse, Yule's I)

```
from nltk.stem.porter \import PorterStemmer
from itertools \import groupby

def words(entry):
    return filter(lambda w: len(w) > 0,
                  [w.strip("0123456789!:,.?(){}[]") for w in entry.split()])

def yule(entry):
    # yule's I measure (the inverse of yule's K measure)
    # higher number is higher diversity - richer vocabulary
    d = {}
    stemmer = PorterStemmer()
    for w in words(entry):
        w = stemmer.stem(w).lower()
        try:
            d[w] += 1
        except KeyError:
            d[w] = 1

    M1 = float(len(d))
    M2 = sum([len(list(g))*(freq**2) for freq,g in groupby(sorted(d.values()))])

    try:
        return (M1*M1)/(M2-M1)
    except ZeroDivisionError:
        return 0
```

For example the output of that function for this post is 21.6



Just wish I knew how to make that middle part more functional-like. I don't like having weird for loops strewn about my code like that.

###### Related articles

- [Improve Your English & Learn New Words With Vocabulary.com](http://www.makeuseof.com/tag/improve-english-learn-words-vocabularycom/) (makeuseof.com)
- [Vocabulary Building](http://annmic.wordpress.com/2011/09/20/vocabulary-building/) (annmic.wordpress.com)
- [Vocabulary Worksheets and Printables](http://www.education.com/worksheets/vocabulary/) (education.com)

[![Enhanced by Zemanta](http://img.zemanta.com/zemified_e.png?x-id=6825c36b-0d62-4d69-a0eb-3b4d98c62cad)](http://www.zemanta.com/ "Enhanced by Zemanta")